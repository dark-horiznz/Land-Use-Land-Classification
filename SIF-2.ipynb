{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f818ea4-d7db-414e-ba99-dd6df0079861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6787873-edcd-44ca-b10b-93d6a91ab1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.keras as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43831d9b-a3fe-4468-ad0b-f654c5c48c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_url = r'/Users/aditya/Desktop/2750'\n",
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "validation_split=0.2\n",
    "rescale=1.0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc2afc7-90fb-4a73-8526-66b5cd2da62e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_split, rescale=rescale)\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_url, image_size=(img_height, img_width), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdb4d5e-1f35-4ced-9848-e0d327801f30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21600 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(img_height, img_width),\n",
    "                                           subset=\"training\",\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "038d6c00-76ce-4a75-b0ca-457b0e8c8d27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(img_height, img_width),\n",
    "                                           subset=\"validation\",\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2baee6ff-4b25-460b-b0bf-346aacece9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    cache = []\n",
    "\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "   \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    \n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = X = Activation('relu')(X, training = training)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7754bfe4-71fb-455f-be43-12a54f15ba3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F2, (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F3, (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), padding = 'valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666372f1-24a1-4e73-93e4-f84644ca6a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "   # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size = (2, 2), name = 'avg_pool')(X)\n",
    "    \n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002957d7-f53c-40d3-955d-8a9054f358c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64,64,3), classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aae9744-a0eb-4468-a95d-e01ed8267b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96593b90-550f-43a8-91dd-e97183f9c15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 11:45:40.305280: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 103s 148ms/step - loss: 1.5147 - accuracy: 0.5553 - val_loss: 1.8943 - val_accuracy: 0.4269\n",
      "Epoch 2/100\n",
      "675/675 [==============================] - 99s 146ms/step - loss: 1.0338 - accuracy: 0.6612 - val_loss: 0.8813 - val_accuracy: 0.7257\n",
      "Epoch 3/100\n",
      "675/675 [==============================] - 289s 429ms/step - loss: 0.8181 - accuracy: 0.7257 - val_loss: 0.7403 - val_accuracy: 0.7354\n",
      "Epoch 4/100\n",
      "675/675 [==============================] - 99s 146ms/step - loss: 0.7501 - accuracy: 0.7593 - val_loss: 1.4039 - val_accuracy: 0.5859\n",
      "Epoch 5/100\n",
      "675/675 [==============================] - 261s 387ms/step - loss: 0.7958 - accuracy: 0.7396 - val_loss: 1.0206 - val_accuracy: 0.6831\n",
      "Epoch 6/100\n",
      "675/675 [==============================] - 99s 147ms/step - loss: 0.6952 - accuracy: 0.7816 - val_loss: 0.7256 - val_accuracy: 0.7641\n",
      "Epoch 7/100\n",
      "675/675 [==============================] - 209s 310ms/step - loss: 0.6596 - accuracy: 0.7962 - val_loss: 0.7863 - val_accuracy: 0.7444\n",
      "Epoch 8/100\n",
      "675/675 [==============================] - 103s 152ms/step - loss: 0.6882 - accuracy: 0.7847 - val_loss: 0.6785 - val_accuracy: 0.7720\n",
      "Epoch 9/100\n",
      "675/675 [==============================] - 101s 150ms/step - loss: 0.4937 - accuracy: 0.8443 - val_loss: 0.5354 - val_accuracy: 0.8354\n",
      "Epoch 10/100\n",
      "675/675 [==============================] - 104s 153ms/step - loss: 0.4909 - accuracy: 0.8442 - val_loss: 0.5087 - val_accuracy: 0.8404\n",
      "Epoch 11/100\n",
      "675/675 [==============================] - 268s 398ms/step - loss: 0.4860 - accuracy: 0.8512 - val_loss: 0.5052 - val_accuracy: 0.8624\n",
      "Epoch 12/100\n",
      "675/675 [==============================] - 100s 147ms/step - loss: 0.3949 - accuracy: 0.8773 - val_loss: 0.4696 - val_accuracy: 0.8535\n",
      "Epoch 13/100\n",
      "675/675 [==============================] - 115s 170ms/step - loss: 0.3451 - accuracy: 0.8900 - val_loss: 0.4980 - val_accuracy: 0.8409\n",
      "Epoch 14/100\n",
      "675/675 [==============================] - 111s 165ms/step - loss: 0.4273 - accuracy: 0.8701 - val_loss: 0.4939 - val_accuracy: 0.8419\n",
      "Epoch 15/100\n",
      "675/675 [==============================] - 104s 154ms/step - loss: 0.3134 - accuracy: 0.9005 - val_loss: 0.4114 - val_accuracy: 0.8659\n",
      "Epoch 16/100\n",
      "675/675 [==============================] - 105s 155ms/step - loss: 0.2754 - accuracy: 0.9138 - val_loss: 0.8222 - val_accuracy: 0.7611\n",
      "Epoch 17/100\n",
      "675/675 [==============================] - 113s 167ms/step - loss: 0.2574 - accuracy: 0.9174 - val_loss: 0.4311 - val_accuracy: 0.8748\n",
      "Epoch 18/100\n",
      "675/675 [==============================] - 108s 159ms/step - loss: 0.3882 - accuracy: 0.8754 - val_loss: 1.2425 - val_accuracy: 0.6415\n",
      "Epoch 19/100\n",
      "675/675 [==============================] - 132s 196ms/step - loss: 0.3250 - accuracy: 0.8878 - val_loss: 0.3431 - val_accuracy: 0.8844\n",
      "Epoch 20/100\n",
      "675/675 [==============================] - 134s 198ms/step - loss: 0.1981 - accuracy: 0.9326 - val_loss: 0.3740 - val_accuracy: 0.8815\n",
      "Epoch 21/100\n",
      "675/675 [==============================] - 123s 182ms/step - loss: 0.1618 - accuracy: 0.9438 - val_loss: 0.3400 - val_accuracy: 0.8944\n",
      "Epoch 22/100\n",
      "675/675 [==============================] - 118s 175ms/step - loss: 0.1562 - accuracy: 0.9462 - val_loss: 0.4499 - val_accuracy: 0.8639\n",
      "Epoch 23/100\n",
      "675/675 [==============================] - 119s 177ms/step - loss: 0.1837 - accuracy: 0.9371 - val_loss: 0.3497 - val_accuracy: 0.8822\n",
      "Epoch 24/100\n",
      "675/675 [==============================] - 116s 171ms/step - loss: 0.1801 - accuracy: 0.9375 - val_loss: 0.4789 - val_accuracy: 0.8591\n",
      "Epoch 25/100\n",
      "675/675 [==============================] - 119s 176ms/step - loss: 0.1262 - accuracy: 0.9573 - val_loss: 0.3755 - val_accuracy: 0.8913\n",
      "Epoch 26/100\n",
      "675/675 [==============================] - 120s 178ms/step - loss: 0.1071 - accuracy: 0.9637 - val_loss: 0.3690 - val_accuracy: 0.8893\n",
      "Epoch 27/100\n",
      "675/675 [==============================] - 124s 183ms/step - loss: 0.1183 - accuracy: 0.9599 - val_loss: 0.3465 - val_accuracy: 0.8939\n",
      "Epoch 28/100\n",
      "675/675 [==============================] - 126s 186ms/step - loss: 0.1019 - accuracy: 0.9656 - val_loss: 0.4337 - val_accuracy: 0.8770\n",
      "Epoch 29/100\n",
      "675/675 [==============================] - 123s 182ms/step - loss: 0.0972 - accuracy: 0.9676 - val_loss: 0.3870 - val_accuracy: 0.8911\n",
      "Epoch 30/100\n",
      "675/675 [==============================] - 123s 182ms/step - loss: 0.1067 - accuracy: 0.9627 - val_loss: 0.3973 - val_accuracy: 0.8909\n",
      "Epoch 31/100\n",
      "675/675 [==============================] - 136s 201ms/step - loss: 0.0799 - accuracy: 0.9731 - val_loss: 0.3904 - val_accuracy: 0.8954\n",
      "Epoch 32/100\n",
      "675/675 [==============================] - 102s 151ms/step - loss: 0.0931 - accuracy: 0.9684 - val_loss: 0.3980 - val_accuracy: 0.8906\n",
      "Epoch 33/100\n",
      "675/675 [==============================] - 112s 165ms/step - loss: 0.0753 - accuracy: 0.9734 - val_loss: 0.5624 - val_accuracy: 0.8524\n",
      "Epoch 34/100\n",
      "675/675 [==============================] - 131s 195ms/step - loss: 0.0866 - accuracy: 0.9714 - val_loss: 0.3706 - val_accuracy: 0.9024\n",
      "Epoch 35/100\n",
      "675/675 [==============================] - 118s 175ms/step - loss: 0.0632 - accuracy: 0.9799 - val_loss: 0.4314 - val_accuracy: 0.8863\n",
      "Epoch 36/100\n",
      "675/675 [==============================] - 120s 178ms/step - loss: 0.0680 - accuracy: 0.9776 - val_loss: 0.5016 - val_accuracy: 0.8685\n",
      "Epoch 37/100\n",
      "675/675 [==============================] - 129s 191ms/step - loss: 0.0467 - accuracy: 0.9838 - val_loss: 0.4061 - val_accuracy: 0.8967\n",
      "Epoch 38/100\n",
      "675/675 [==============================] - 133s 198ms/step - loss: 0.0559 - accuracy: 0.9817 - val_loss: 0.4508 - val_accuracy: 0.8920\n",
      "Epoch 39/100\n",
      "675/675 [==============================] - 130s 193ms/step - loss: 0.0622 - accuracy: 0.9795 - val_loss: 0.4635 - val_accuracy: 0.8846\n",
      "Epoch 40/100\n",
      "675/675 [==============================] - 128s 190ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.3914 - val_accuracy: 0.8993\n",
      "Epoch 41/100\n",
      "675/675 [==============================] - 132s 195ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.4104 - val_accuracy: 0.8928\n",
      "Epoch 42/100\n",
      "675/675 [==============================] - 123s 183ms/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 0.4053 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "675/675 [==============================] - 310s 460ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.3832 - val_accuracy: 0.9007\n",
      "Epoch 44/100\n",
      "675/675 [==============================] - 543s 805ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.4072 - val_accuracy: 0.8956\n",
      "Epoch 45/100\n",
      "675/675 [==============================] - 100s 148ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.4073 - val_accuracy: 0.9048\n",
      "Epoch 46/100\n",
      "675/675 [==============================] - 102s 151ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.5498 - val_accuracy: 0.8765\n",
      "Epoch 47/100\n",
      "675/675 [==============================] - 113s 167ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.5106 - val_accuracy: 0.8806\n",
      "Epoch 48/100\n",
      "675/675 [==============================] - 164s 243ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.5080 - val_accuracy: 0.8956\n",
      "Epoch 49/100\n",
      "675/675 [==============================] - 197s 292ms/step - loss: 0.0413 - accuracy: 0.9856 - val_loss: 0.4498 - val_accuracy: 0.8939\n",
      "Epoch 50/100\n",
      "675/675 [==============================] - 187s 277ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.4755 - val_accuracy: 0.8915\n",
      "Epoch 51/100\n",
      "675/675 [==============================] - 196s 290ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.4798 - val_accuracy: 0.8906\n",
      "Epoch 52/100\n",
      "675/675 [==============================] - 199s 295ms/step - loss: 0.0376 - accuracy: 0.9880 - val_loss: 0.4536 - val_accuracy: 0.8991\n",
      "Epoch 53/100\n",
      "675/675 [==============================] - 175s 260ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.5109 - val_accuracy: 0.8865\n",
      "Epoch 54/100\n",
      "675/675 [==============================] - 149s 221ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 0.4661 - val_accuracy: 0.8930\n",
      "Epoch 55/100\n",
      "675/675 [==============================] - 118s 174ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.4440 - val_accuracy: 0.8991\n",
      "Epoch 56/100\n",
      "675/675 [==============================] - 121s 179ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.5294 - val_accuracy: 0.8874\n",
      "Epoch 57/100\n",
      "675/675 [==============================] - 125s 185ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.4723 - val_accuracy: 0.8881\n",
      "Epoch 58/100\n",
      "675/675 [==============================] - 118s 174ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.4921 - val_accuracy: 0.9015\n",
      "Epoch 59/100\n",
      "675/675 [==============================] - 111s 165ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 0.4904 - val_accuracy: 0.8911\n",
      "Epoch 60/100\n",
      "675/675 [==============================] - 113s 168ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.4807 - val_accuracy: 0.9009\n",
      "Epoch 61/100\n",
      "675/675 [==============================] - 119s 176ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.4781 - val_accuracy: 0.8985\n",
      "Epoch 62/100\n",
      "675/675 [==============================] - 125s 186ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.4857 - val_accuracy: 0.9009\n",
      "Epoch 63/100\n",
      "675/675 [==============================] - 126s 187ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.5101 - val_accuracy: 0.8994\n",
      "Epoch 64/100\n",
      "675/675 [==============================] - 128s 189ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.5679 - val_accuracy: 0.8876\n",
      "Epoch 65/100\n",
      "675/675 [==============================] - 123s 182ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.5080 - val_accuracy: 0.8896\n",
      "Epoch 66/100\n",
      "675/675 [==============================] - 115s 171ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 0.4439 - val_accuracy: 0.9072\n",
      "Epoch 67/100\n",
      "675/675 [==============================] - 117s 173ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.4515 - val_accuracy: 0.8996\n",
      "Epoch 68/100\n",
      "675/675 [==============================] - 125s 186ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.4381 - val_accuracy: 0.9067\n",
      "Epoch 69/100\n",
      "675/675 [==============================] - 120s 178ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.6567 - val_accuracy: 0.8683\n",
      "Epoch 70/100\n",
      "675/675 [==============================] - 122s 181ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.4261 - val_accuracy: 0.9065\n",
      "Epoch 71/100\n",
      "675/675 [==============================] - 126s 187ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.4831 - val_accuracy: 0.9024\n",
      "Epoch 72/100\n",
      "675/675 [==============================] - 132s 196ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.4855 - val_accuracy: 0.8931\n",
      "Epoch 73/100\n",
      "675/675 [==============================] - 126s 187ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.5627 - val_accuracy: 0.8811\n",
      "Epoch 74/100\n",
      "675/675 [==============================] - 135s 200ms/step - loss: 0.0328 - accuracy: 0.9901 - val_loss: 0.5207 - val_accuracy: 0.8885\n",
      "Epoch 75/100\n",
      "675/675 [==============================] - 145s 215ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.5000 - val_accuracy: 0.8991\n",
      "Epoch 76/100\n",
      "675/675 [==============================] - 147s 217ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.5081 - val_accuracy: 0.8956\n",
      "Epoch 77/100\n",
      "675/675 [==============================] - 147s 217ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.5324 - val_accuracy: 0.8967\n",
      "Epoch 78/100\n",
      "675/675 [==============================] - 142s 211ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.5801 - val_accuracy: 0.8789\n",
      "Epoch 79/100\n",
      "675/675 [==============================] - 138s 204ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.4773 - val_accuracy: 0.8963\n",
      "Epoch 80/100\n",
      "675/675 [==============================] - 136s 201ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.5340 - val_accuracy: 0.8928\n",
      "Epoch 81/100\n",
      "675/675 [==============================] - 138s 204ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.4938 - val_accuracy: 0.8983\n",
      "Epoch 82/100\n",
      "675/675 [==============================] - 138s 204ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.5517 - val_accuracy: 0.8935\n",
      "Epoch 83/100\n",
      "675/675 [==============================] - 132s 196ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.4872 - val_accuracy: 0.9046\n",
      "Epoch 84/100\n",
      "675/675 [==============================] - 147s 218ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.5028 - val_accuracy: 0.8989\n",
      "Epoch 85/100\n",
      "675/675 [==============================] - 136s 201ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.5096 - val_accuracy: 0.9015\n",
      "Epoch 86/100\n",
      "675/675 [==============================] - 138s 205ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.5288 - val_accuracy: 0.8913\n",
      "Epoch 87/100\n",
      "675/675 [==============================] - 136s 202ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.6496 - val_accuracy: 0.8854\n",
      "Epoch 88/100\n",
      "675/675 [==============================] - 132s 196ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.5304 - val_accuracy: 0.8941\n",
      "Epoch 89/100\n",
      "675/675 [==============================] - 140s 208ms/step - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.5024 - val_accuracy: 0.9043\n",
      "Epoch 90/100\n",
      "675/675 [==============================] - 138s 205ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.4965 - val_accuracy: 0.9020\n",
      "Epoch 91/100\n",
      "675/675 [==============================] - 133s 198ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.4872 - val_accuracy: 0.8994\n",
      "Epoch 92/100\n",
      "675/675 [==============================] - 286s 424ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.5330 - val_accuracy: 0.8965\n",
      "Epoch 93/100\n",
      "675/675 [==============================] - 100s 149ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.5332 - val_accuracy: 0.8926\n",
      "Epoch 94/100\n",
      "675/675 [==============================] - 104s 154ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.5141 - val_accuracy: 0.8974\n",
      "Epoch 95/100\n",
      "675/675 [==============================] - 148s 219ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 0.5277 - val_accuracy: 0.9059\n",
      "Epoch 96/100\n",
      "675/675 [==============================] - 133s 197ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.5476 - val_accuracy: 0.8909\n",
      "Epoch 97/100\n",
      "675/675 [==============================] - 133s 196ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.4818 - val_accuracy: 0.9117\n",
      "Epoch 98/100\n",
      "675/675 [==============================] - 147s 219ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.6129 - val_accuracy: 0.8872\n",
      "Epoch 99/100\n",
      "675/675 [==============================] - 110s 162ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.4937 - val_accuracy: 0.9100\n",
      "Epoch 100/100\n",
      "675/675 [==============================] - 113s 167ms/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.6313 - val_accuracy: 0.8911\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d532546-db9c-4a04-b9f1-03b770e23792",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 64)   9472        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 15, 15, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 15, 15, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 15, 15, 256)  16640       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 15, 15, 256)  16640       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 15, 15, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 15, 15, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 15, 15, 256)  0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 15, 15, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 15, 15, 64)   16448       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 15, 15, 64)   36928       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 15, 15, 256)  16640       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 15, 15, 256)  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 15, 15, 256)  0           ['activation_3[0][0]',           \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 15, 15, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 15, 15, 64)   16448       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 15, 15, 64)   36928       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 15, 15, 256)  0           ['activation_6[0][0]',           \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 15, 15, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 128)   512         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 8, 8, 128)   512         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 8, 8, 512)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 128)   512         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 128)   512         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 512)    0           ['activation_12[0][0]',          \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 512)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 128)   512         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 128)   512         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 512)    0           ['activation_15[0][0]',          \n",
      "                                                                  'batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 512)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 8, 8, 128)   512         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 8, 8, 128)   512         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 512)    0           ['activation_18[0][0]',          \n",
      "                                                                  'batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 8, 8, 512)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 4, 4, 1024)   0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 4, 4, 1024)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 4, 4, 1024)   0           ['activation_24[0][0]',          \n",
      "                                                                  'batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 4, 4, 1024)   0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4, 4, 1024)   0           ['activation_27[0][0]',          \n",
      "                                                                  'batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4, 4, 1024)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 4, 4, 1024)   0           ['activation_30[0][0]',          \n",
      "                                                                  'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 4, 4, 1024)   0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 4, 4, 1024)   0           ['activation_33[0][0]',          \n",
      "                                                                  'batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 4, 4, 1024)   0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4, 4, 1024)   0           ['activation_36[0][0]',          \n",
      "                                                                  'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 4, 4, 1024)   0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_45[0][0]', \n",
      "                                                                  'batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 2, 2, 2048)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 2, 2, 2048)   0           ['activation_42[0][0]',          \n",
      "                                                                  'batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 2, 2, 2048)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 2, 2, 2048)   0           ['activation_45[0][0]',          \n",
      "                                                                  'batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 2, 2, 2048)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D)    (None, 1, 1, 2048)   0           ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           20490       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fc028b-ba2d-4088-b1b6-93f409304cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lulc_50_epoch/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lulc_50_epoch/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('lulc_100_epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19cbdaaf-9046-4a8f-a56a-2ef346773917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16.53\u001b[39m, \u001b[38;5;241m11.69\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1653x1169 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['val_accuracy'])\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_title('Accuracy over epoch')\n",
    "ax1.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_title('Loss over epoch')\n",
    "ax2.legend(['Train', 'Test'], loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252a5e46-4311-49f9-a88a-ecb318e8383c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m y_true\u001b[38;5;241m.\u001b[39mappend(label_batch)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# compute predictions\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(image_batch)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# append predicted labels\u001b[39;00m\n\u001b[1;32m     11\u001b[0m y_pred\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39margmax(preds, axis \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for i, (image_batch, label_batch) in enumerate(test_dataset):   # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    preds = model.predict(image_batch)\n",
    "    # append predicted labels\n",
    "    y_pred.append(np.argmax(preds, axis =  1))\n",
    "    if i==300:\n",
    "        break\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "correct_labels = np.argmax(correct_labels, axis=1)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
    "cm = confusion_matrix(correct_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265369cf-7758-4e96-9bf0-436a122649e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(correct_labels, predicted_labels)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(cm, classes,\n\u001b[1;32m      3\u001b[0m                         normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                         title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                         figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      6\u001b[0m                         cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    This function prints and plots the confusion matrix.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Normalization can be applied by setting `normalize=True`.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(correct_labels, predicted_labels)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        figsize=(10, 10),\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "plot_confusion_matrix(cm, train_dataset.class_indices, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9a7c5-1af2-4e9f-9771-0c9391b9be3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_metal",
   "language": "python",
   "name": "tf_metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
